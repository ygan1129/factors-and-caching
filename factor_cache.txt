Note: The implementation I've written essentially assumes that all the integers are distinct
      and positive.  If we have duplicate integers, I would store duplicate keys in the
      dictionary as a tuple, and then write a custom print method that takes this into
      account.  The initial sort in the wrapper function memoize takes O(n log n) time, and
      the simple implementation I've used will find factors in n^2/4 modulus calculations, as
      opposed to an implementation that produces all n^2/2 pairs and applies the modulus to 
      all of them.

1. For the cache implementation, I have just serialized my Python dictionaries as JSON
   files for readability.  JSON keys are strings, so I made a cosmetic change to turn
   them back into integers when printing.  More generally, if I did not use the built-in
   JSON encoder and decoder, a generic implementation would write the following to a
   csv file:
       1) Put a string of the (sorted) 

2. Once loaded from the JSON file, python dicts have constant time (amortized) lookup,
   so the speed issues come from serializing and deserializing the JSON file at the
   beginning and end of factor_cache evaluation.  JSON parsing is fairly slow in this
   regard, but is human readable and easy to implement.  For very large caches, I
   would try to make a SQL database, which I might implement in the following way:
   	 1) One table is just two identical columns that include ALL the numbers seen 
	    in ALL arrays so far
	 2) Another table whose name is related to the input array, which has two columns
	    that map the left side of the previous table to the right side ie. [20, 5],
	    [20, 10], etc.

3. Reversed functionality does not change the caching algorithm, as the initial key is
   just a stringified and tuple-fied version of the input array in the JSON implementation.
   For the SQL table implementation, this also does not change, as we can query the factor
   table in the exact same way.
